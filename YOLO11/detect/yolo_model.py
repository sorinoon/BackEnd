# import cv2
# import numpy as np
# from ultralytics import YOLO

# # YOLO ëª¨ë¸ ë¡œë“œ
# model = YOLO("C:/Users/joonh/OneDrive/ë°”íƒ• í™”ë©´/YOLO11/runs/detect/train/weights/best.pt") 

# # ì¹´ë©”ë¼ ì´ˆì  ê±°ë¦¬ ì„¤ì •
# FOCAL_LENGTH = 800
# REFERENCE_OBJECT_WIDTH = 50  # ê¸°ì¤€ ë¬¼ì²´ì˜ ì‹¤ì œ ë„ˆë¹„ (cm)
# WARNING_DISTANCE = 300  # 3m (300cm)

# # ê°ì²´ë³„ ê²½ê³  ìƒíƒœ ì €ì¥
# object_warnings = {}

# def generate_frames(video_path):
#     cap = cv2.VideoCapture(video_path)

#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break

#         results = model(frame)
#         new_warnings = {}

#         for result in results:
#             for i, box in enumerate(result.boxes):
#                 x1, y1, x2, y2 = map(int, box.xyxy[0])
#                 class_id = int(box.cls[0])
#                 class_name = model.names[class_id]

#                 # ë¬¼ì²´ì˜ ë„ˆë¹„(í”½ì…€)
#                 object_width_pixels = abs(x2 - x1)

#                 # ê±°ë¦¬ ê³„ì‚°
#                 if object_width_pixels > 0:
#                     distance = (REFERENCE_OBJECT_WIDTH * FOCAL_LENGTH) / object_width_pixels
#                 else:
#                     distance = None  

#                 # ê°ì²´ ID ìƒì„±
#                 obj_id = f"{class_name}_{(x1 + x2) // 2}_{(y1 + y2) // 2}"
#                 new_warnings[obj_id] = distance

#                 # 3m ì´ë‚´ ì ‘ê·¼ ì‹œ ê²½ê³  ì¶œë ¥
#                 if distance and distance <= WARNING_DISTANCE:
#                     if obj_id not in object_warnings or object_warnings[obj_id] > WARNING_DISTANCE:
#                         print(f"âš ï¸ {class_name} ê°ì²´ê°€ 3m ì´ë‚´ì— ìˆìŠµë‹ˆë‹¤!")

#                 # ê°ì§€ ê²°ê³¼ í‘œì‹œ
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#                 cv2.putText(frame, f"{class_name}: {distance:.2f} cm" if distance else class_name, 
#                             (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

#         object_warnings.update(new_warnings)

#         _, buffer = cv2.imencode('.jpg', frame)
#         frame_bytes = buffer.tobytes()

#         yield (b'--frame\r\n'
#                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

#     cap.release()
# import cv2
# import numpy as np
# from ultralytics import YOLO

# # YOLO ëª¨ë¸ ë¡œë“œ
# model = YOLO("C:/Users/joonh/OneDrive/ë°”íƒ• í™”ë©´/YOLO11/runs/detect/train/weights/best.pt") 

# # ì¹´ë©”ë¼ ì´ˆì  ê±°ë¦¬ ì„¤ì •
# FOCAL_LENGTH = 800
# REFERENCE_OBJECT_WIDTH = 50  # ê¸°ì¤€ ë¬¼ì²´ì˜ ì‹¤ì œ ë„ˆë¹„ (cm)
# WARNING_DISTANCE = 300  # 3m (300cm)

# # ê°ì²´ë³„ ê²½ê³  ìƒíƒœ ì €ì¥
# object_warnings = {}

# def generate_frames(video_path):
#     cap = cv2.VideoCapture(video_path)

#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break

#         results = model(frame)
#         new_warnings = {}

#         closest_obj = None  # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì •ë³´
#         closest_distance = float('inf')  # ê°€ì¥ ê°€ê¹Œìš´ ê±°ë¦¬ ì´ˆê¸°í™”

#         for result in results:
#             for box in result.boxes:
#                 x1, y1, x2, y2 = map(int, box.xyxy[0])
#                 class_id = int(box.cls[0])
#                 class_name = model.names[class_id]

#                 object_width_pixels = abs(x2 - x1)

#                 if object_width_pixels > 0:
#                     distance = (REFERENCE_OBJECT_WIDTH * FOCAL_LENGTH) / object_width_pixels
#                 else:
#                     distance = None  

#                 obj_id = f"{class_name}_{(x1 + x2) // 2}_{(y1 + y2) // 2}"
#                 new_warnings[obj_id] = distance

#                 # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì°¾ê¸°
#                 if distance and distance < closest_distance:
#                     closest_distance = distance
#                     closest_obj = (class_name, distance, obj_id)

#                 # ê°ì§€ëœ ê°ì²´ ë°•ìŠ¤ ë° ê±°ë¦¬ í‘œì‹œ
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#                 cv2.putText(frame, f"{class_name}: {distance:.2f} cm" if distance else class_name, 
#                             (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

#         # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ê°€ 3m ì´ë‚´ì¼ ê²½ìš° ê²½ê³  ì¶œë ¥ (í•œ ë²ˆë§Œ)
#         if closest_obj and closest_distance <= WARNING_DISTANCE:
#             class_name, distance, obj_id = closest_obj
#             if obj_id not in object_warnings or object_warnings[obj_id] > WARNING_DISTANCE:
#                 print(f"âš ï¸ ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´: {class_name} ({distance:.2f} cm)")

#         object_warnings.update(new_warnings)

#         _, buffer = cv2.imencode('.jpg', frame)
#         frame_bytes = buffer.tobytes()

#         yield (b'--frame\r\n'
#                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

#     cap.release()

# import cv2
# import numpy as np
# from ultralytics import YOLO

# # YOLO ëª¨ë¸ ë¡œë“œ
# #model = YOLO("C:/Users/joonh/OneDrive/ë°”íƒ• í™”ë©´/YOLO11/runs/detect/train/weights/best.pt") 

# model = YOLO("C:/Users/hansung/Documents/GitHub/BackEnd/YOLO11/runs/detect/train/weights/best.pt")

# # ì¹´ë©”ë¼ ì´ˆì  ê±°ë¦¬ ì„¤ì •
# FOCAL_LENGTH = 800
# REFERENCE_OBJECT_WIDTH = 50  # ê¸°ì¤€ ë¬¼ì²´ì˜ ì‹¤ì œ ë„ˆë¹„ (cm)
# WARNING_DISTANCE = 300  # 3m (300cm)

# # ê°ì²´ë³„ ê²½ê³  ìƒíƒœ ì €ì¥
# object_warnings = {}

# def generate_frames(source=0):  # ğŸ”¹ ê¸°ë³¸ê°’ìœ¼ë¡œ ì›¹ìº  ì‚¬ìš© (0ë²ˆ ì¹´ë©”ë¼)
#     cap = cv2.VideoCapture(source)
#     #cap.set(cv2.CAP_PROP_FPS, 10)

#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break

#         results = model(frame)  # YOLO ëª¨ë¸ ì ìš©
#         new_warnings = {}

#         closest_obj = None  
#         closest_distance = float('inf')  

#         for result in results:
#             for box in result.boxes:
#                 x1, y1, x2, y2 = map(int, box.xyxy[0])
#                 class_id = int(box.cls[0])
#                 class_name = model.names[class_id]

#                 object_width_pixels = abs(x2 - x1)

#                 if object_width_pixels > 0:
#                     distance = (REFERENCE_OBJECT_WIDTH * FOCAL_LENGTH) / object_width_pixels
#                 else:
#                     distance = None  

#                 obj_id = f"{class_name}_{(x1 + x2) // 2}_{(y1 + y2) // 2}"
#                 new_warnings[obj_id] = distance

#                 # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì°¾ê¸°
#                 if distance and distance < closest_distance:
#                     closest_distance = distance
#                     closest_obj = (class_name, distance, obj_id)

#                 # ê°ì§€ëœ ê°ì²´ ë°•ìŠ¤ ë° ê±°ë¦¬ í‘œì‹œ
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#                 cv2.putText(frame, f"{class_name}: {distance:.2f} cm" if distance else class_name, 
#                             (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

#         # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ê°€ 3m ì´ë‚´ì¼ ê²½ìš° ê²½ê³  ì¶œë ¥ (í•œ ë²ˆë§Œ)
#         if closest_obj and closest_distance <= WARNING_DISTANCE:
#             class_name, distance, obj_id = closest_obj
#             if obj_id not in object_warnings or object_warnings[obj_id] > WARNING_DISTANCE:
#                 print(f"âš ï¸ ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´: {class_name} ({distance:.2f} cm)")

#         object_warnings.update(new_warnings)

#         _, buffer = cv2.imencode('.jpg', frame)
#         frame_bytes = buffer.tobytes()

#         yield (b'--frame\r\n'
#                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

#     cv2.waitKey(10000000000)
#     cap.release()

# import cv2
# import numpy as np
# import requests
# import pygame
# import io
# from ultralytics import YOLO

# # ë„¤ì´ë²„ í´ë¡œë°” TTS API ì„¤ì •
# # NAVER_CLIENT_ID = "8419bd554f"  # ë„¤ì´ë²„ í´ë¡œë°” API í´ë¼ì´ì–¸íŠ¸ ID
# # NAVER_CLIENT_SECRET = "p0e0HlCPeyiyCnsVhSICyMQQG4uI31zqW7B4KPO3"  # ë„¤ì´ë²„ í´ë¡œë°” API í´ë¼ì´ì–¸íŠ¸ Secret
# TTS_URL = "https://naveropenapi.apigw.ntruss.com/voice/v1/tts"

# # YOLO ëª¨ë¸ ë¡œë“œ
# #model = YOLO("C:/Users/hansung/Documents/GitHub/BackEnd/YOLO11/runs/detect/train/weights/best.pt")

# # ëª¨ë¸ ë¡œë“œ
# model = YOLO("runs/detect/train/weights/best.pt")


# # ì¹´ë©”ë¼ ì´ˆì  ê±°ë¦¬ ì„¤ì •
# FOCAL_LENGTH = 800
# REFERENCE_OBJECT_WIDTH = 50  # ê¸°ì¤€ ë¬¼ì²´ì˜ ì‹¤ì œ ë„ˆë¹„ (cm)
# WARNING_DISTANCE = 300  # 3m (300cm)

# # ê°ì²´ë³„ ê²½ê³  ìƒíƒœ ì €ì¥
# object_warnings = {}

# # def play_tts(text):
# #     """ë„¤ì´ë²„ í´ë¡œë°” TTS APIë¥¼ í˜¸ì¶œí•˜ê³  ìŒì„±ì„ ì¬ìƒ"""
# #     headers = {
# #         "X-NCP-APIGW-API-KEY-ID": "8419bd554f",
# #         "X-NCP-APIGW-API-KEY": "p0e0HlCPeyiyCnsVhSICyMQQG4uI31zqW7B4KPO3",
# #         "Content-Type": "application/x-www-form-urlencoded",
# #     }
# #     data = {
# #         "speaker": "mijin",  # ì—¬ì„± ìŒì„± (ë‹¤ë¥¸ ì˜µì…˜: "jinho" - ë‚¨ì„± ìŒì„±)
# #         "speed": "0",  # ìŒì„± ì†ë„ ì¡°ì ˆ (-5 ~ +5)
# #         "text": text,
# #     }

# #     response = requests.post(TTS_URL, headers=headers, data=data)
# #     if response.status_code == 200:
# #         pygame.mixer.init()
# #         audio_stream = io.BytesIO(response.content)
# #         pygame.mixer.music.load(audio_stream)
# #         pygame.mixer.music.play()
# #         while pygame.mixer.music.get_busy():
# #             continue  # ìŒì„±ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
# #     else:
# #         print("TTS ìš”ì²­ ì‹¤íŒ¨:", response.text)

# def play_tts(text):
#     url = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"
    
#     # í´ë¡œë°” TTS APIì˜ ì¸ì¦ ì •ë³´ (í´ë¼ì´ì–¸íŠ¸ ID, í´ë¼ì´ì–¸íŠ¸ ì‹œí¬ë¦¿)
#     client_id = "8419bd554f"
#     client_secret = "1tI9xbELi4xyGC426tPQljd9HPTuPiKELzA3vxx8"
    
#     headers = {
#         'X-Naver-Client-Id': client_id,
#         'X-Naver-Client-Secret': client_secret,
#         'Content-Type': 'application/json'
#     }
    
#     # ìš”ì²­ ë°ì´í„° (textê°€ ìŒì„±ìœ¼ë¡œ ë³€í™˜ë  ë¬¸ì¥)
#     data = {
#         "speaker": "mijin",   # ì‚¬ìš©í•  ìŒì„± ì„ íƒ (ì˜ˆ: 'clova', 'mijin', 'jinho', ë“±)
#         "speed": 0,           # ìŒì„± ì†ë„
#         "text": text     # ë³€í™˜í•  í…ìŠ¤íŠ¸
#     }
    
#     response = requests.post(url, headers=headers, json=data)
    
#     if response.status_code == 200:
#         audio_content = response.content
#         # ìŒì„± íŒŒì¼ë¡œ ì €ì¥í•˜ê±°ë‚˜ ë°”ë¡œ ì¬ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#         with open("warning_audio.mp3", "wb") as audio_file:
#             audio_file.write(audio_content)
        
#         # ì˜ˆì‹œ: os.system('mpg321 warning_audio.mp3') ë˜ëŠ” ë‹¤ë¥¸ ë°©ë²•ìœ¼ë¡œ ìŒì„± íŒŒì¼ì„ ì¬ìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
#         # ì˜ˆ: pygame ë˜ëŠ” pydub ë“±ì„ ì‚¬ìš©í•˜ì—¬ ìŒì„±ì„ ì§ì ‘ ì¬ìƒí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
#     else:
#         print(f"Error: {response.status_code}, {response.text}")


# # def generate_frames(source=0):  # ğŸ”¹ ê¸°ë³¸ê°’ìœ¼ë¡œ ì›¹ìº  ì‚¬ìš© (0ë²ˆ ì¹´ë©”ë¼)
# #     cap = cv2.VideoCapture(source)

# #     while cap.isOpened():
# #         ret, frame = cap.read()
# #         if not ret:
# #             break

# #         results = model(frame)  # YOLO ëª¨ë¸ ì ìš©
# #         new_warnings = {}

# #         closest_obj = None  
# #         closest_distance = float('inf')  

# #         for result in results:
# #             for box in result.boxes:
# #                 x1, y1, x2, y2 = map(int, box.xyxy[0])
# #                 class_id = int(box.cls[0])
# #                 class_name = model.names[class_id]

# #                 object_width_pixels = abs(x2 - x1)

# #                 if object_width_pixels > 0:
# #                     distance = (REFERENCE_OBJECT_WIDTH * FOCAL_LENGTH) / object_width_pixels
# #                 else:
# #                     distance = None  

# #                 obj_id = f"{class_name}_{(x1 + x2) // 2}_{(y1 + y2) // 2}"
# #                 new_warnings[obj_id] = distance

# #                 # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì°¾ê¸°
# #                 if distance and distance < closest_distance:
# #                     closest_distance = distance
# #                     closest_obj = (class_name, distance, obj_id)

# #                 # ê°ì§€ëœ ê°ì²´ ë°•ìŠ¤ ë° ê±°ë¦¬ í‘œì‹œ
# #                 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
# #                 cv2.putText(frame, f"{class_name}: {distance:.2f} cm" if distance else class_name, 
# #                             (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

# #         # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ê°€ 3m ì´ë‚´ì¼ ê²½ìš° ê²½ê³ ìŒ ì¶œë ¥ (í•œ ë²ˆë§Œ)
# #         if closest_obj and closest_distance <= WARNING_DISTANCE:
# #             class_name, distance, obj_id = closest_obj
# #             if obj_id not in object_warnings or object_warnings[obj_id] > WARNING_DISTANCE:
# #                 warning_text = f"ê²½ê³ ! {class_name}ì´ {distance:.0f}cm ì•ì— ìˆìŠµë‹ˆë‹¤."
# #                 print(f"âš ï¸ {warning_text}")
# #                 play_tts(warning_text)  # ğŸ”¹ ë„¤ì´ë²„ TTS í˜¸ì¶œí•˜ì—¬ ê²½ê³ ìŒ ì¶œë ¥

# #         object_warnings.update(new_warnings)

# #         _, buffer = cv2.imencode('.jpg', frame)
# #         frame_bytes = buffer.tobytes()

# #         yield (b'--frame\r\n'
# #                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

# #     cv2.waitKey(10000000000)
# #     cap.release()

# def generate_frames(source=0):  # ğŸ”¹ ê¸°ë³¸ê°’ìœ¼ë¡œ ì›¹ìº  ì‚¬ìš© (0ë²ˆ ì¹´ë©”ë¼)
#     cap = cv2.VideoCapture(source)

#     while cap.isOpened():
#         ret, frame = cap.read()
#         if not ret:
#             break

#         results = model(frame)  # YOLO ëª¨ë¸ ì ìš©
#         new_warnings = {}

#         closest_obj = None  
#         closest_distance = float('inf')  

#         for result in results:
#             for box in result.boxes:
#                 x1, y1, x2, y2 = map(int, box.xyxy[0])
#                 class_id = int(box.cls[0])
#                 class_name = model.names[class_id]

#                 object_width_pixels = abs(x2 - x1)

#                 if object_width_pixels > 0:
#                     distance = (REFERENCE_OBJECT_WIDTH * FOCAL_LENGTH) / object_width_pixels
#                 else:
#                     distance = None  

#                 obj_id = f"{class_name}_{(x1 + x2) // 2}_{(y1 + y2) // 2}"
#                 new_warnings[obj_id] = distance

#                 # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì°¾ê¸°
#                 if distance and distance < closest_distance:
#                     closest_distance = distance
#                     closest_obj = (class_name, distance, obj_id)

#                 # ê°ì§€ëœ ê°ì²´ ë°•ìŠ¤ ë° ê±°ë¦¬ í‘œì‹œ
#                 cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
#                 cv2.putText(frame, f"{class_name}: {distance:.2f} cm" if distance else class_name, 
#                             (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

#         # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ê°€ 3m ì´ë‚´ì¼ ê²½ìš° ê²½ê³ ìŒ ì¶œë ¥ (í•œ ë²ˆë§Œ)
#         if closest_obj and closest_distance <= WARNING_DISTANCE:
#             class_name, distance, obj_id = closest_obj
#             if obj_id not in object_warnings or object_warnings[obj_id] > WARNING_DISTANCE:
#                 warning_text = f"ê²½ê³ ! {class_name}ì´ {distance:.0f}cm ì•ì— ìˆìŠµë‹ˆë‹¤."
#                 print(f"âš ï¸ {warning_text}")
#                 play_tts(warning_text)  # ğŸ”¹ ë„¤ì´ë²„ TTS í˜¸ì¶œí•˜ì—¬ ê²½ê³ ìŒ ì¶œë ¥

#         object_warnings.update(new_warnings)

#         _, buffer = cv2.imencode('.jpg', frame)
#         frame_bytes = buffer.tobytes()

#         yield (b'--frame\r\n'
#                b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')

#     cv2.waitKey(10000000000)
#     cap.release()

import cv2
import numpy as np
import requests
import pygame
import io
from ultralytics import YOLO
import urllib.request

# ë„¤ì´ë²„ í´ë¡œë°” TTS API ì„¤ì •
TTS_URL = "https://naveropenapi.apigw.ntruss.com/voice/v1/tts"

# YOLO ëª¨ë¸ ë¡œë“œ
model = YOLO("runs/detect/train/weights/best.pt")

# ì¹´ë©”ë¼ ì´ˆì  ê±°ë¦¬ ì„¤ì •
FOCAL_LENGTH = 800
REFERENCE_OBJECT_WIDTH = 50  # ê¸°ì¤€ ë¬¼ì²´ì˜ ì‹¤ì œ ë„ˆë¹„ (cm)
WARNING_DISTANCE = 300  # 3m (300cm)

# ê°ì²´ë³„ ê²½ê³  ìƒíƒœ ì €ì¥
object_warnings = {}

import pygame
import io
import urllib.request

def play_tts(text):
    # í´ë¡œë°” TTS APIì˜ ì¸ì¦ ì •ë³´ (í´ë¼ì´ì–¸íŠ¸ ID, í´ë¼ì´ì–¸íŠ¸ ì‹œí¬ë¦¿)
    client_id = "8419bd554f"
    client_secret = "1tI9xbELi4xyGC426tPQljd9HPTuPiKELzA3vxx8"
    
    encText = text
    data = "speaker=nara&volume=0&speed=0&pitch=0&format=mp3&text=" + encText
    url = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"
    request = urllib.request.Request(url)
    request.add_header("X-NCP-APIGW-API-KEY-ID", client_id)
    request.add_header("X-NCP-APIGW-API-KEY", client_secret)
    
    try:
        response = urllib.request.urlopen(request, data=data.encode('utf-8'))
        rescode = response.getcode()  # getcode()ë¡œ ì‘ë‹µ ì½”ë“œ í™•ì¸
        
        if rescode == 200:
            print("TTS mp3 ì €ì¥")
            response_body = response.read()
            
            # ì´í›„ pygameì„ ì´ìš©í•´ mp3ë¥¼ ì¬ìƒ
            pygame.mixer.init()
            audio_stream = io.BytesIO(response_body)
            pygame.mixer.music.load(audio_stream)
            pygame.mixer.music.play()
            
            while pygame.mixer.music.get_busy():
                continue  # ìŒì„±ì´ ëë‚  ë•Œê¹Œì§€ ëŒ€ê¸°
        else:
            print(f"Error Code: {rescode}")
    
    except Exception as e:
        print(f"Error: {e}")


def generate_frames(source=0):  # ğŸ”¹ ê¸°ë³¸ê°’ìœ¼ë¡œ ì›¹ìº  ì‚¬ìš© (0ë²ˆ ì¹´ë©”ë¼)
    cap = cv2.VideoCapture(source)

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        results = model(frame)  # YOLO ëª¨ë¸ ì ìš©
        new_warnings = {}

        closest_obj = None  
        closest_distance = float('inf')  

        for result in results:
            for box in result.boxes:
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                class_id = int(box.cls[0])
                class_name = model.names[class_id]

                object_width_pixels = abs(x2 - x1)

                if object_width_pixels > 0:
                    distance = (REFERENCE_OBJECT_WIDTH * FOCAL_LENGTH) / object_width_pixels
                else:
                    distance = None  

                obj_id = f"{class_name}_{(x1 + x2) // 2}_{(y1 + y2) // 2}"
                new_warnings[obj_id] = distance

                # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ ì°¾ê¸°
                if distance and distance < closest_distance:
                    closest_distance = distance
                    closest_obj = (class_name, distance, obj_id)

                # ê°ì§€ëœ ê°ì²´ ë°•ìŠ¤ ë° ê±°ë¦¬ í‘œì‹œ
                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(frame, f"{class_name}: {distance:.2f} cm" if distance else class_name, 
                            (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)

        # ê°€ì¥ ê°€ê¹Œìš´ ê°ì²´ê°€ 3m ì´ë‚´ì¼ ê²½ìš° ê²½ê³ ìŒ ì¶œë ¥ (í•œ ë²ˆë§Œ)
        if closest_obj and closest_distance <= WARNING_DISTANCE:
            class_name, distance, obj_id = closest_obj
            if obj_id not in object_warnings or object_warnings[obj_id] > WARNING_DISTANCE:
                warning_text = f"ê²½ê³ ! {class_name}ì´ {distance:.0f}cm ì•ì— ìˆìŠµë‹ˆë‹¤."
                print(f"âš ï¸ {warning_text}")
                play_tts(warning_text)  # ğŸ”¹ ë„¤ì´ë²„ TTS í˜¸ì¶œí•˜ì—¬ ê²½ê³ ìŒ ì¶œë ¥

        object_warnings.update(new_warnings)

        _, buffer = cv2.imencode('.jpg', frame)
        frame_bytes = buffer.tobytes()

        yield (b'--frame\r\n'
               b'Content-Type: image/jpeg\r\n\r\n' + frame_bytes + b'\r\n')
    cap.release()
